{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder as ohc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "np.set_printoptions(formatter={'float_kind':\"{:3.2f}\".format})\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_regression\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the default file as a data frame\n",
    "default = pd.read_csv(\"default.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below accomplishes the same thing as the onehot encoding for me it was easier to use and more intuitive, however, for the sake of the assignment I shall use the onehot ecoding to follow the instructions.\n",
    "However, feel free to remove the hashes below to see the result of getting the dummy variables dropping the first of the binary set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting dummy variables and dropping first value for student\n",
    "#df_encoded = pd.get_dummies(default[\"student\"], drop_first=True, prefix=\"student\")\n",
    "\n",
    "# Concatenate the original DataFrame with the one-hot encoded DataFrame\n",
    "#default_enc = pd.concat([default, df_encoded], axis=1)\n",
    "\n",
    "# Drop the original \"student\" column\n",
    "#default_enc = default_enc.drop([\"student\"], axis=1)\n",
    "#default_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. One hot encoding the Student Data and Drop first if Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00],\n",
       "       [1.00],\n",
       "       [0.00],\n",
       "       ...,\n",
       "       [0.00],\n",
       "       [0.00],\n",
       "       [1.00]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# onehot encode student column\n",
    "enc = ohc(drop='if_binary',sparse=False)\n",
    "df_encoded=enc.fit_transform(default[[\"student\"]])\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'sparse_output'or 'sparse':Will return sparse matrix if set True else will return an array. The default is set to true, however since I set it to false over here I got an array for df_encoded.\n",
    "\n",
    "‘if_binary’ : drops the first category in each feature with two categories. Features with 1 or more than 2 categories are left intact. In this case it is binary so it drops the Student_No.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['No', 'Yes'], dtype=object)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enclabels=enc.categories_\n",
    "\n",
    "enclabels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here avove I can see that the labels are binary and the first is **No** which got dropped when we used the enc.fit_transform on the student column after defining enc in the previous line of code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      S_Yes\n",
       "0       0.0\n",
       "1       1.0\n",
       "2       0.0\n",
       "3       0.0\n",
       "4       0.0\n",
       "...     ...\n",
       "9995    0.0\n",
       "9996    0.0\n",
       "9997    0.0\n",
       "9998    0.0\n",
       "9999    1.0\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with the one-hot encoded column\n",
    "df_encoded = pd.DataFrame(df_encoded)\n",
    "# we rename the column to S_Yes for the yes value under student column\n",
    "df_encoded = df_encoded.rename(columns={0:'S_Yes'})\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>S_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>711.555020</td>\n",
       "      <td>52992.378914</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>757.962918</td>\n",
       "      <td>19660.721768</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>845.411989</td>\n",
       "      <td>58636.156984</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1569.009053</td>\n",
       "      <td>36669.112365</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>200.922183</td>\n",
       "      <td>16862.952321</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 default student      balance        income  S_Yes\n",
       "0              1      No      No   729.526495  44361.625074    0.0\n",
       "1              2      No     Yes   817.180407  12106.134700    1.0\n",
       "2              3      No      No  1073.549164  31767.138947    0.0\n",
       "3              4      No      No   529.250605  35704.493935    0.0\n",
       "4              5      No      No   785.655883  38463.495879    0.0\n",
       "...          ...     ...     ...          ...           ...    ...\n",
       "9995        9996      No      No   711.555020  52992.378914    0.0\n",
       "9996        9997      No      No   757.962918  19660.721768    0.0\n",
       "9997        9998      No      No   845.411989  58636.156984    0.0\n",
       "9998        9999      No      No  1569.009053  36669.112365    0.0\n",
       "9999       10000      No     Yes   200.922183  16862.952321    1.0\n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with the one-hot encoded columns\n",
    "df_encoded = pd.concat([default, df_encoded], axis=1)\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>S_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>No</td>\n",
       "      <td>711.555020</td>\n",
       "      <td>52992.378914</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>No</td>\n",
       "      <td>757.962918</td>\n",
       "      <td>19660.721768</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>No</td>\n",
       "      <td>845.411989</td>\n",
       "      <td>58636.156984</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>No</td>\n",
       "      <td>1569.009053</td>\n",
       "      <td>36669.112365</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>No</td>\n",
       "      <td>200.922183</td>\n",
       "      <td>16862.952321</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 default      balance        income  S_Yes\n",
       "0              1      No   729.526495  44361.625074    0.0\n",
       "1              2      No   817.180407  12106.134700    1.0\n",
       "2              3      No  1073.549164  31767.138947    0.0\n",
       "3              4      No   529.250605  35704.493935    0.0\n",
       "4              5      No   785.655883  38463.495879    0.0\n",
       "...          ...     ...          ...           ...    ...\n",
       "9995        9996      No   711.555020  52992.378914    0.0\n",
       "9996        9997      No   757.962918  19660.721768    0.0\n",
       "9997        9998      No   845.411989  58636.156984    0.0\n",
       "9998        9999      No  1569.009053  36669.112365    0.0\n",
       "9999       10000      No   200.922183  16862.952321    1.0\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the original \"student\" column\n",
    "df_encoded = df_encoded.drop([\"student\"], axis=1)\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into features and target variables \n",
    "x = df_encoded[['balance','income','S_Yes']]\n",
    "\n",
    "#Below is default the target \n",
    "y = df_encoded['default']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPlit the training and testing sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, train_size=0.8, test_size=0.2, random_state=5)\n",
    "\n",
    "# Initialize the scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "X_train = sc.fit_transform(X_train)\n",
    "\n",
    "# Use the same scaler to transform the test data\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean and standard deviation is the default scaling parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y=pd.get_dummies(default[\"default\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: best parameters: {'n_neighbors': 20}\n",
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "model = KNeighborsClassifier()\n",
    "#Fit models with k = 1, 2, 3, 10, 20, 500 neighbors. \n",
    "#Explain your results; particularly for k = 1 and large values of k.\n",
    "#Why does the performance not decrease below a threshold?\n",
    "k_values = [i for i in (1,2,3,10,20,500)]\n",
    "\n",
    "# grid search\n",
    "param_grid = {'n_neighbors':k_values}\n",
    "grid = GridSearchCV(model, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Grid Search: best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "# accuracy of best model with confidence interval\n",
    "best_model = grid.best_estimator_\n",
    "predict_y = best_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, predict_y)\n",
    "print(\"Accuracy: {:3.2f}\".format(acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encoding:\n",
    "\n",
    "One-hot encoding is used for categorical variables, converting them into binary vectors. For example, if you have a categorical variable with three classes ('A', 'B', 'C'), one-hot encoding creates three binary columns where each column corresponds to one class.\n",
    "Data leakage in one-hot encoding is generally not a concern. The reason is that each category is represented by its own binary column, and the encoding process is typically applied independently to each subset of data (training, validation, test). The transformation doesn't involve any computation across rows, so there's no risk of information from the test set influencing the encoding process.\n",
    "\n",
    "Scaling (Standardization or Normalization):\n",
    "\n",
    "Scaling involves transforming numerical features to a standard scale, often using the mean and standard deviation (for standardization) or minimum and maximum values (for normalization).\n",
    "Data leakage in scaling can occur if the mean and standard deviation (or min and max) are computed using information from the test set. This would mean that the scaling parameters are influenced by the distribution of the test set, potentially leading to over-optimistic performance estimates.\n",
    "To avoid data leakage, the mean and standard deviation (or other scaling parameters) should be computed solely on the training set and then applied to the test set.\n",
    "\n",
    "In summary, while one-hot encoding is generally less prone to data leakage concerns, it's crucial to be mindful of how scaling is applied, ensuring that the scaling parameters are derived solely from the training set to maintain the integrity of the model evaluation on unseen data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Repeating exercise 3 without the drop argument in the one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sparse equals false turns it into an array \n",
    "enco = ohc(sparse=False)\n",
    "df_enco=enco.fit_transform(default[[\"student\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00, 0.00],\n",
       "       [0.00, 1.00],\n",
       "       [1.00, 0.00],\n",
       "       ...,\n",
       "       [1.00, 0.00],\n",
       "       [1.00, 0.00],\n",
       "       [0.00, 1.00]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# called this to see what encoding and sparse accomplised \n",
    "df_enco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['No', 'Yes'], dtype=object)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm the labels of the ecoded variable\n",
    "enlabels=enco.categories_\n",
    "\n",
    "enlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "default        object\n",
       "balance       float64\n",
       "income        float64\n",
       "(No,)         float64\n",
       "(Yes,)        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with the one-hot encoded column\n",
    "df_enco = pd.DataFrame(df_enco, columns=enlabels)\n",
    "# Create a DataFrame with the one-hot encoded columns\n",
    "df_enco = pd.concat([default, df_enco], axis=1)\n",
    "# Drop the original \"student\" column\n",
    "df_enco = df_enco.drop([\"student\"], axis=1)\n",
    "df_enco.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into features and target variables \n",
    "x1 = df_enco.drop([\"default\"], axis=1)\n",
    "# we are going to use the previous Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPlit the training and testing sets \n",
    "X_traind, X_testd, y_train, y_test = train_test_split(x1, y, train_size=0.8, test_size=0.2, random_state=5)\n",
    "\n",
    "# Initialize the scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "X_traind = sc.fit_transform(X_traind)\n",
    "\n",
    "# Use the same scaler to transform the test data\n",
    "X_testd = sc.transform(X_testd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: best parameters: {'n_neighbors': 10}\n",
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "#fitting the train data on the grid \n",
    "grid.fit(X_traind, y_train)\n",
    "print(\"Grid Search: best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "# accuracy of best model with confidence interval\n",
    "best_model1 = grid.best_estimator_\n",
    "predict_y1 = best_model1.predict(X_testd)\n",
    "accd = accuracy_score(y_test, predict_y1)\n",
    "print(\"Accuracy: {:3.2f}\".format(accd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees and SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest Cover "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the forest cover type data set as a data frame \n",
    "covert = pd.read_csv(\"covtype.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581007</th>\n",
       "      <td>2396</td>\n",
       "      <td>153</td>\n",
       "      <td>20</td>\n",
       "      <td>85</td>\n",
       "      <td>17</td>\n",
       "      <td>108</td>\n",
       "      <td>240</td>\n",
       "      <td>237</td>\n",
       "      <td>118</td>\n",
       "      <td>837</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581008</th>\n",
       "      <td>2391</td>\n",
       "      <td>152</td>\n",
       "      <td>19</td>\n",
       "      <td>67</td>\n",
       "      <td>12</td>\n",
       "      <td>95</td>\n",
       "      <td>240</td>\n",
       "      <td>237</td>\n",
       "      <td>119</td>\n",
       "      <td>845</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581009</th>\n",
       "      <td>2386</td>\n",
       "      <td>159</td>\n",
       "      <td>17</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>236</td>\n",
       "      <td>241</td>\n",
       "      <td>130</td>\n",
       "      <td>854</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581010</th>\n",
       "      <td>2384</td>\n",
       "      <td>170</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>230</td>\n",
       "      <td>245</td>\n",
       "      <td>143</td>\n",
       "      <td>864</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581011</th>\n",
       "      <td>2383</td>\n",
       "      <td>165</td>\n",
       "      <td>13</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>231</td>\n",
       "      <td>244</td>\n",
       "      <td>141</td>\n",
       "      <td>875</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581012 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0            2596      51      3                               258   \n",
       "1            2590      56      2                               212   \n",
       "2            2804     139      9                               268   \n",
       "3            2785     155     18                               242   \n",
       "4            2595      45      2                               153   \n",
       "...           ...     ...    ...                               ...   \n",
       "581007       2396     153     20                                85   \n",
       "581008       2391     152     19                                67   \n",
       "581009       2386     159     17                                60   \n",
       "581010       2384     170     15                                60   \n",
       "581011       2383     165     13                                60   \n",
       "\n",
       "        Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                                    0                              510   \n",
       "1                                   -6                              390   \n",
       "2                                   65                             3180   \n",
       "3                                  118                             3090   \n",
       "4                                   -1                              391   \n",
       "...                                ...                              ...   \n",
       "581007                              17                              108   \n",
       "581008                              12                               95   \n",
       "581009                               7                               90   \n",
       "581010                               5                               90   \n",
       "581011                               4                               67   \n",
       "\n",
       "        Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0                 221             232            148   \n",
       "1                 220             235            151   \n",
       "2                 234             238            135   \n",
       "3                 238             238            122   \n",
       "4                 220             234            150   \n",
       "...               ...             ...            ...   \n",
       "581007            240             237            118   \n",
       "581008            240             237            119   \n",
       "581009            236             241            130   \n",
       "581010            230             245            143   \n",
       "581011            231             244            141   \n",
       "\n",
       "        Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "0                                     6279  ...            0            0   \n",
       "1                                     6225  ...            0            0   \n",
       "2                                     6121  ...            0            0   \n",
       "3                                     6211  ...            0            0   \n",
       "4                                     6172  ...            0            0   \n",
       "...                                    ...  ...          ...          ...   \n",
       "581007                                 837  ...            0            0   \n",
       "581008                                 845  ...            0            0   \n",
       "581009                                 854  ...            0            0   \n",
       "581010                                 864  ...            0            0   \n",
       "581011                                 875  ...            0            0   \n",
       "\n",
       "        Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0                 0            0            0            0            0   \n",
       "1                 0            0            0            0            0   \n",
       "2                 0            0            0            0            0   \n",
       "3                 0            0            0            0            0   \n",
       "4                 0            0            0            0            0   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "581007            0            0            0            0            0   \n",
       "581008            0            0            0            0            0   \n",
       "581009            0            0            0            0            0   \n",
       "581010            0            0            0            0            0   \n",
       "581011            0            0            0            0            0   \n",
       "\n",
       "        Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0                 0            0           5  \n",
       "1                 0            0           5  \n",
       "2                 0            0           2  \n",
       "3                 0            0           2  \n",
       "4                 0            0           5  \n",
       "...             ...          ...         ...  \n",
       "581007            0            0           3  \n",
       "581008            0            0           3  \n",
       "581009            0            0           3  \n",
       "581010            0            0           3  \n",
       "581011            0            0           3  \n",
       "\n",
       "[581012 rows x 55 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is a huge dataset and I would like to see as much as I can \n",
    "covert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Elevation                             int64\n",
       "Aspect                                int64\n",
       "Slope                                 int64\n",
       "Horizontal_Distance_To_Hydrology      int64\n",
       "Vertical_Distance_To_Hydrology        int64\n",
       "Horizontal_Distance_To_Roadways       int64\n",
       "Hillshade_9am                         int64\n",
       "Hillshade_Noon                        int64\n",
       "Hillshade_3pm                         int64\n",
       "Horizontal_Distance_To_Fire_Points    int64\n",
       "Wilderness_Area1                      int64\n",
       "Wilderness_Area2                      int64\n",
       "Wilderness_Area3                      int64\n",
       "Wilderness_Area4                      int64\n",
       "Soil_Type1                            int64\n",
       "Soil_Type2                            int64\n",
       "Soil_Type3                            int64\n",
       "Soil_Type4                            int64\n",
       "Soil_Type5                            int64\n",
       "Soil_Type6                            int64\n",
       "Soil_Type7                            int64\n",
       "Soil_Type8                            int64\n",
       "Soil_Type9                            int64\n",
       "Soil_Type10                           int64\n",
       "Soil_Type11                           int64\n",
       "Soil_Type12                           int64\n",
       "Soil_Type13                           int64\n",
       "Soil_Type14                           int64\n",
       "Soil_Type15                           int64\n",
       "Soil_Type16                           int64\n",
       "Soil_Type17                           int64\n",
       "Soil_Type18                           int64\n",
       "Soil_Type19                           int64\n",
       "Soil_Type20                           int64\n",
       "Soil_Type21                           int64\n",
       "Soil_Type22                           int64\n",
       "Soil_Type23                           int64\n",
       "Soil_Type24                           int64\n",
       "Soil_Type25                           int64\n",
       "Soil_Type26                           int64\n",
       "Soil_Type27                           int64\n",
       "Soil_Type28                           int64\n",
       "Soil_Type29                           int64\n",
       "Soil_Type30                           int64\n",
       "Soil_Type31                           int64\n",
       "Soil_Type32                           int64\n",
       "Soil_Type33                           int64\n",
       "Soil_Type34                           int64\n",
       "Soil_Type35                           int64\n",
       "Soil_Type36                           int64\n",
       "Soil_Type37                           int64\n",
       "Soil_Type38                           int64\n",
       "Soil_Type39                           int64\n",
       "Soil_Type40                           int64\n",
       "Cover_Type                            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at the data types \n",
    "covert.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I wanted to use this method below for sampling randomly but found a better way to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_size = 20000\n",
    "\n",
    "#cover_samp = covert.sample(n=sample_size, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into features and target variables \n",
    "x2 = covert.drop([\"Cover_Type\"], axis=1)\n",
    "y1 = covert[\"Cover_Type\"]\n",
    "y1 = covert[\"Cover_Type\"].astype(\"category\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This make classification method below is a better way of sampling and I can choose the number of columns as well as observations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the make classification library \n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# I am choosing 10000 observations and 25 columns \n",
    "x2,y1 = make_classification(n_samples=10000, n_features=25, random_state=42)\n",
    "# SPlit the training and testing sets \n",
    "X_traint, X_testt, y_traint, y_testt = train_test_split(x2, y1, train_size=0.7, test_size=0.3, random_state=3)\n",
    "\n",
    "# Initialize the scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "X_traint = sc.fit_transform(X_traint)\n",
    "\n",
    "# Use the same scaler to transform the test data\n",
    "X_testt = sc.transform(X_testt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.4 s, sys: 8.06 ms, total: 35.4 s\n",
      "Wall time: 35.4 s\n",
      "Grid Search: best parameters: {'criterion': 'entropy', 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "# decision trees\n",
    "model = DecisionTreeClassifier(random_state=40)\n",
    "\n",
    "# grid search\n",
    "param_grid = {'max_depth': list(range(1,21)), 'criterion': ['entropy','gini'] }\n",
    "grid = GridSearchCV(model, param_grid, cv=5)\n",
    "%time grid.fit(X_traint, y_traint)\n",
    "print(\"Grid Search: best parameters: {}\".format(grid.best_params_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "# accuracy of best model\n",
    "best_model = grid.best_estimator_\n",
    "predictt_y = best_model.predict(X_testt)\n",
    "acct = accuracy_score(y_testt, predictt_y)\n",
    "print(\"Accuracy: {:3.2f}\".format(acct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I had an accuracy of 93% when I choose this combination of onservations and features and I played with this several times where it trained for 2 minutes and gave 76% accuracy and when I did the whole dataset it took about 16 minutes with 97% accuracy. So my current sampling and it's accuracy performed very well considering it took just 35 secs to complete training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am choosing 8000 observations and 23 columns \n",
    "\n",
    "x2,y1 = make_classification(n_samples=8000, n_features=23, random_state=42)\n",
    "#Split data into 70-30 training and testing \n",
    "X_trainl, X_testl, y_trainl, y_testl = train_test_split(x2, y1, train_size=0.7, test_size=0.3, random_state=3)\n",
    "\n",
    "# Create a pipeline with a scaler and LinearSVC\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linearsvc', LinearSVC())])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using pipelines in grid searches \n",
    "\n",
    "param_grid = {'linearsvc__C': [1, 2, 4],    \n",
    "              'linearsvc__tol': [1e-4, 1e-5, 1e-6],\n",
    "             'linearsvc__max_iter': [10000, 20000]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 22s, sys: 1min 20s, total: 3min 43s\n",
      "Wall time: 1min 18s\n",
      "Grid Search: best parameters: {'linearsvc__C': 1, 'linearsvc__max_iter': 10000, 'linearsvc__tol': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grids = GridSearchCV(pipeline, param_grid=param_grid, cv=5, scoring = 'accuracy')\n",
    "# timing the completion of training\n",
    "%time grids.fit(X_trainl, y_trainl)\n",
    "\n",
    "# Print the best hyperparameters found by GridSearchCV\n",
    "print(\"Grid Search: best parameters: {}\".format(grids.best_params_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "best_param = grids.best_estimator_\n",
    "\n",
    "ypreds = best_param.predict(X_testl)\n",
    "accs = accuracy_score(y_testl, ypreds)\n",
    "print(\"Accuracy: {:3.2f}\".format(accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is a more complex model than the tree that is why it took a longer time to complete training even with fewer observations and features. However, I didn't want my sample size to be so small that I would get a good enough picture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housing Prices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the housing data as a data frame \n",
    "housing = pd.read_csv('ames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MS_SubClass</th>\n",
       "      <th>MS_Zoning</th>\n",
       "      <th>Lot_Frontage</th>\n",
       "      <th>Lot_Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot_Shape</th>\n",
       "      <th>Land_Contour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>Lot_Config</th>\n",
       "      <th>...</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc_Feature</th>\n",
       "      <th>Misc_Val</th>\n",
       "      <th>Mo_Sold</th>\n",
       "      <th>Year_Sold</th>\n",
       "      <th>Sale_Type</th>\n",
       "      <th>Sale_Condition</th>\n",
       "      <th>Sale_Price</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>141</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Slightly_Irregular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "      <td>-93.619754</td>\n",
       "      <td>42.054035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_High_Density</td>\n",
       "      <td>80</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>Minimum_Privacy</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "      <td>-93.619756</td>\n",
       "      <td>42.053014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>81</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Slightly_Irregular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "      <td>-93.619387</td>\n",
       "      <td>42.052659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One_Story_1946_and_Newer_All_Styles</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>93</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>No_Fence</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "      <td>-93.617320</td>\n",
       "      <td>42.051245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two_Story_1946_and_Newer</td>\n",
       "      <td>Residential_Low_Density</td>\n",
       "      <td>74</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>No_Alley_Access</td>\n",
       "      <td>Slightly_Irregular</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>Minimum_Privacy</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900</td>\n",
       "      <td>-93.638933</td>\n",
       "      <td>42.060899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           MS_SubClass                 MS_Zoning  \\\n",
       "0  One_Story_1946_and_Newer_All_Styles   Residential_Low_Density   \n",
       "1  One_Story_1946_and_Newer_All_Styles  Residential_High_Density   \n",
       "2  One_Story_1946_and_Newer_All_Styles   Residential_Low_Density   \n",
       "3  One_Story_1946_and_Newer_All_Styles   Residential_Low_Density   \n",
       "4             Two_Story_1946_and_Newer   Residential_Low_Density   \n",
       "\n",
       "   Lot_Frontage  Lot_Area Street            Alley           Lot_Shape  \\\n",
       "0           141     31770   Pave  No_Alley_Access  Slightly_Irregular   \n",
       "1            80     11622   Pave  No_Alley_Access             Regular   \n",
       "2            81     14267   Pave  No_Alley_Access  Slightly_Irregular   \n",
       "3            93     11160   Pave  No_Alley_Access             Regular   \n",
       "4            74     13830   Pave  No_Alley_Access  Slightly_Irregular   \n",
       "\n",
       "  Land_Contour Utilities Lot_Config  ...            Fence Misc_Feature  \\\n",
       "0          Lvl    AllPub     Corner  ...         No_Fence         None   \n",
       "1          Lvl    AllPub     Inside  ...  Minimum_Privacy         None   \n",
       "2          Lvl    AllPub     Corner  ...         No_Fence         Gar2   \n",
       "3          Lvl    AllPub     Corner  ...         No_Fence         None   \n",
       "4          Lvl    AllPub     Inside  ...  Minimum_Privacy         None   \n",
       "\n",
       "  Misc_Val Mo_Sold Year_Sold Sale_Type Sale_Condition Sale_Price  Longitude  \\\n",
       "0        0       5      2010       WD          Normal     215000 -93.619754   \n",
       "1        0       6      2010       WD          Normal     105000 -93.619756   \n",
       "2    12500       6      2010       WD          Normal     172000 -93.619387   \n",
       "3        0       4      2010       WD          Normal     244000 -93.617320   \n",
       "4        0       3      2010       WD          Normal     189900 -93.638933   \n",
       "\n",
       "    Latitude  \n",
       "0  42.054035  \n",
       "1  42.053014  \n",
       "2  42.052659  \n",
       "3  42.051245  \n",
       "4  42.060899  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the first 5 rows and all the columns \n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lot_Frontage</th>\n",
       "      <th>Lot_Area</th>\n",
       "      <th>Year_Built</th>\n",
       "      <th>Year_Remod_Add</th>\n",
       "      <th>Mas_Vnr_Area</th>\n",
       "      <th>BsmtFin_SF_1</th>\n",
       "      <th>BsmtFin_SF_2</th>\n",
       "      <th>Bsmt_Unf_SF</th>\n",
       "      <th>Total_Bsmt_SF</th>\n",
       "      <th>First_Flr_SF</th>\n",
       "      <th>...</th>\n",
       "      <th>Enclosed_Porch</th>\n",
       "      <th>Three_season_porch</th>\n",
       "      <th>Screen_Porch</th>\n",
       "      <th>Pool_Area</th>\n",
       "      <th>Misc_Val</th>\n",
       "      <th>Mo_Sold</th>\n",
       "      <th>Year_Sold</th>\n",
       "      <th>Sale_Price</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141</td>\n",
       "      <td>31770</td>\n",
       "      <td>1960</td>\n",
       "      <td>1960</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>441</td>\n",
       "      <td>1080</td>\n",
       "      <td>1656</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>215000</td>\n",
       "      <td>-93.619754</td>\n",
       "      <td>42.054035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>11622</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>144</td>\n",
       "      <td>270</td>\n",
       "      <td>882</td>\n",
       "      <td>896</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>105000</td>\n",
       "      <td>-93.619756</td>\n",
       "      <td>42.053014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81</td>\n",
       "      <td>14267</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>406</td>\n",
       "      <td>1329</td>\n",
       "      <td>1329</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>172000</td>\n",
       "      <td>-93.619387</td>\n",
       "      <td>42.052659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>11160</td>\n",
       "      <td>1968</td>\n",
       "      <td>1968</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1045</td>\n",
       "      <td>2110</td>\n",
       "      <td>2110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>244000</td>\n",
       "      <td>-93.617320</td>\n",
       "      <td>42.051245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74</td>\n",
       "      <td>13830</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>928</td>\n",
       "      <td>928</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>189900</td>\n",
       "      <td>-93.638933</td>\n",
       "      <td>42.060899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>37</td>\n",
       "      <td>7937</td>\n",
       "      <td>1984</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>1003</td>\n",
       "      <td>1003</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>142500</td>\n",
       "      <td>-93.604776</td>\n",
       "      <td>41.988964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>0</td>\n",
       "      <td>8885</td>\n",
       "      <td>1983</td>\n",
       "      <td>1983</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>239</td>\n",
       "      <td>864</td>\n",
       "      <td>902</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>131000</td>\n",
       "      <td>-93.602680</td>\n",
       "      <td>41.988314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>62</td>\n",
       "      <td>10441</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>575</td>\n",
       "      <td>912</td>\n",
       "      <td>970</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>132000</td>\n",
       "      <td>-93.606847</td>\n",
       "      <td>41.986510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>77</td>\n",
       "      <td>10010</td>\n",
       "      <td>1974</td>\n",
       "      <td>1975</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>195</td>\n",
       "      <td>1389</td>\n",
       "      <td>1389</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>170000</td>\n",
       "      <td>-93.600190</td>\n",
       "      <td>41.990921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>74</td>\n",
       "      <td>9627</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>94</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>238</td>\n",
       "      <td>996</td>\n",
       "      <td>996</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>188000</td>\n",
       "      <td>-93.599996</td>\n",
       "      <td>41.989265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2930 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lot_Frontage  Lot_Area  Year_Built  Year_Remod_Add  Mas_Vnr_Area  \\\n",
       "0              141     31770        1960            1960           112   \n",
       "1               80     11622        1961            1961             0   \n",
       "2               81     14267        1958            1958           108   \n",
       "3               93     11160        1968            1968             0   \n",
       "4               74     13830        1997            1998             0   \n",
       "...            ...       ...         ...             ...           ...   \n",
       "2925            37      7937        1984            1984             0   \n",
       "2926             0      8885        1983            1983             0   \n",
       "2927            62     10441        1992            1992             0   \n",
       "2928            77     10010        1974            1975             0   \n",
       "2929            74      9627        1993            1994            94   \n",
       "\n",
       "      BsmtFin_SF_1  BsmtFin_SF_2  Bsmt_Unf_SF  Total_Bsmt_SF  First_Flr_SF  \\\n",
       "0                2             0          441           1080          1656   \n",
       "1                6           144          270            882           896   \n",
       "2                1             0          406           1329          1329   \n",
       "3                1             0         1045           2110          2110   \n",
       "4                3             0          137            928           928   \n",
       "...            ...           ...          ...            ...           ...   \n",
       "2925             3             0          184           1003          1003   \n",
       "2926             2           324          239            864           902   \n",
       "2927             3             0          575            912           970   \n",
       "2928             1           123          195           1389          1389   \n",
       "2929             4             0          238            996           996   \n",
       "\n",
       "      ...  Enclosed_Porch  Three_season_porch  Screen_Porch  Pool_Area  \\\n",
       "0     ...               0                   0             0          0   \n",
       "1     ...               0                   0           120          0   \n",
       "2     ...               0                   0             0          0   \n",
       "3     ...               0                   0             0          0   \n",
       "4     ...               0                   0             0          0   \n",
       "...   ...             ...                 ...           ...        ...   \n",
       "2925  ...               0                   0             0          0   \n",
       "2926  ...               0                   0             0          0   \n",
       "2927  ...               0                   0             0          0   \n",
       "2928  ...               0                   0             0          0   \n",
       "2929  ...               0                   0             0          0   \n",
       "\n",
       "      Misc_Val  Mo_Sold  Year_Sold  Sale_Price  Longitude   Latitude  \n",
       "0            0        5       2010      215000 -93.619754  42.054035  \n",
       "1            0        6       2010      105000 -93.619756  42.053014  \n",
       "2        12500        6       2010      172000 -93.619387  42.052659  \n",
       "3            0        4       2010      244000 -93.617320  42.051245  \n",
       "4            0        3       2010      189900 -93.638933  42.060899  \n",
       "...        ...      ...        ...         ...        ...        ...  \n",
       "2925         0        3       2006      142500 -93.604776  41.988964  \n",
       "2926         0        6       2006      131000 -93.602680  41.988314  \n",
       "2927       700        7       2006      132000 -93.606847  41.986510  \n",
       "2928         0        4       2006      170000 -93.600190  41.990921  \n",
       "2929         0       11       2006      188000 -93.599996  41.989265  \n",
       "\n",
       "[2930 rows x 35 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting just the numerical data types to avoid encoding \n",
    "housing2 = housing.select_dtypes(include='number')\n",
    "housing2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data set into predictors and a response\n",
    "feat = housing2.drop(['Sale_Price'], axis = 1)\n",
    "targ = housing2['Sale_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a subset of the data to avoid long run times so we random sample\n",
    "#But here I used all the features since it is not as much as the forest data\n",
    "feat,targ = make_regression(n_samples=2000, n_features=35, random_state=42)\n",
    "#split into 70% training and 30% testing \n",
    "X_trainh, X_testh, y_trainh, y_testh = train_test_split(feat,targ, train_size=0.7, test_size=0.3, random_state=3)\n",
    "\n",
    "# Initialize the scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "X_trainh = sc.fit_transform(X_trainh)\n",
    "\n",
    "# Use the same scaler to transform the test data\n",
    "X_testh = sc.transform(X_testh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor for Housing Prediction Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.4 s, sys: 12.6 ms, total: 30.4 s\n",
      "Wall time: 30.4 s\n",
      "Grid Search: best parameters: {'criterion': 'entropy', 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "# decision trees\n",
    "regtree = DecisionTreeRegressor(random_state=40)\n",
    "\n",
    "# grid search\n",
    "param_grid = {'max_depth': list(range(1,21)), 'criterion': ['mse','mae'] }\n",
    "gridtree = GridSearchCV(regtree, param_grid, cv=5)\n",
    "#time the output of the best parameters and what they are\n",
    "%time gridtree.fit(X_trainh, y_trainh)\n",
    "print(\"Grid Search: best parameters: {}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree mse: 19773.97\n",
      "tree mae: 112.54\n",
      "tree r2: 0.52\n"
     ]
    }
   ],
   "source": [
    "# metrics of best model\n",
    "best_modelr = gridtree.best_estimator_\n",
    "predictr_y = best_modelr.predict(X_testh)\n",
    "mse = mean_squared_error(y_testh, predictr_y)\n",
    "mae = mean_absolute_error(y_testh, predictr_y)\n",
    "r2 = r2_score(y_testh, predictr_y)\n",
    "\n",
    "#printing the metrics of the best model \n",
    "print(\"tree mse: {:3.2f}\".format(mse))\n",
    "print(\"tree mae: {:3.2f}\".format(mae))\n",
    "print(\"tree r2: {:3.2f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem and the ones that follow are regression problems so I am going to have a different set of metrics for continous values in my target variable and I chose the following few. \n",
    "\n",
    "\n",
    "- MSE is the average of squared differences between observed and predicted values. It penalizes larger errors more heavily than MAE\n",
    "\n",
    "- MAE represents the average absolute difference between the observed and predicted values. It is robust to outliers.\n",
    "\n",
    "- R-squared measures the proportion of the variance in the dependent variable that is predictable from the independent variables. It ranges from 0 to 1, with higher values indicating better fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR from SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a random sample of the housing data\n",
    "feat1,targ1 = make_regression(n_samples=2000, n_features=35, random_state=42)\n",
    "#splitting the samples into 70% training and 30% testing\n",
    "X_trainhs, X_tesths, y_trainhs, y_tesths = train_test_split(feat1,targ1, train_size=0.7, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a pipeline with a scaler and SVR\n",
    "pipelinesvr = Pipeline([('scaler', StandardScaler()),\n",
    "    ('svr', SVR())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Using pipelines in grid searches \n",
    "\n",
    "param_grid = {'svr__C': [1, 2, 4],    \n",
    "              'svr__kernel': [\"rbf\", \"poly\", \"linear\"],\n",
    "              'svr__gamma':[0.001,0.01,0.1]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.6 s, sys: 10.9 ms, total: 21.6 s\n",
      "Wall time: 21.6 s\n",
      "Grid Search: best parameters: {'svr__C': 4, 'svr__gamma': 0.001, 'svr__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "gridsvr = GridSearchCV(pipelinesvr, param_grid=param_grid, cv=5)\n",
    "#timing the completion of training\n",
    "%time gridsvr.fit(X_trainhs, y_trainhs)\n",
    "\n",
    "# Print the best hyperparameters found by GridSearchCV\n",
    "print(\"Grid Search: best parameters: {}\".format(gridsvr.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svr mse: 0.00\n",
      "svr mae: 0.04\n",
      "svr r2: 1.00\n"
     ]
    }
   ],
   "source": [
    "# metrics of best model\n",
    "best_modelsvr = gridsvr.best_estimator_\n",
    "predictsvr_y = best_modelsvr.predict(X_tesths)\n",
    "svrmse = mean_squared_error(y_tesths, predictsvr_y)\n",
    "svrmae = mean_absolute_error(y_tesths, predictsvr_y)\n",
    "svr2 = r2_score(y_tesths, predictsvr_y)\n",
    "\n",
    "# printing metrics of best model\n",
    "\n",
    "print(\"svr mse: {:3.2f}\".format(svrmse))\n",
    "print(\"svr mae: {:3.2f}\".format(svrmae))\n",
    "print(\"svr r2: {:3.2f}\".format(svr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this SVR model we see that there are no differences between the true and predicted value and the linear Kernel performed better than the polynomial and Radial. we could not score a higher r2 value (coefficient of determination). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVR from SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a random sample of the housing data\n",
    "feat,targ = make_regression(n_samples=2930, n_features=35, random_state=42)\n",
    "#splitting the samples into 70% training and 30% testing\n",
    "X_trainh, X_testh, y_trainh, y_testh = train_test_split(feat,targ, train_size=0.7, test_size=0.3, random_state=42)\n",
    "# Create a pipeline with a scaler and LinearSVR\n",
    "pipelinelsvr = Pipeline([('scaler', StandardScaler()),\n",
    "    ('linearsvr', LinearSVR())])\n",
    "\n",
    "#Using pipelines in grid searches \n",
    "param_grid = {'linearsvr__C': [0.01, 0.02, 0.1,1],    \n",
    "              'linearsvr__tol': [1e-2,1e-3,1e-4, 1e-5, 1e-6],\n",
    "             'linearsvr__max_iter': [1000, 2000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.3 s, sys: 13.8 s, total: 26.1 s\n",
      "Wall time: 1.65 s\n",
      "Grid Search: best parameters: {'linearsvr__C': 1, 'linearsvr__max_iter': 1000, 'linearsvr__tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "gridlsvr = GridSearchCV(pipelinelsvr, param_grid=param_grid, cv=5)\n",
    "# timing the completion of training\n",
    "%time gridlsvr.fit(X_trainh, y_trainh)\n",
    "\n",
    "# Print the best hyperparameters found by GridSearchCV\n",
    "print(\"Grid Search: best parameters: {}\".format(gridlsvr.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearsvr mse: 0.00\n",
      "linearsvr mae: 0.00\n",
      "linearsvr r2: 1.00\n"
     ]
    }
   ],
   "source": [
    "# metrics of best model\n",
    "best_modellsvr = gridlsvr.best_estimator_\n",
    "predictlsvr_y = best_modellsvr.predict(X_testh)\n",
    "lsvrmse = mean_squared_error(y_testh, predictlsvr_y)\n",
    "lsvrmae = mean_absolute_error(y_testh, predictlsvr_y)\n",
    "lsvr2 = r2_score(y_testh, predictlsvr_y)\n",
    "\n",
    "# printing metrics of best model\n",
    "\n",
    "print(\"linearsvr mse: {:3.2f}\".format(lsvrmse))\n",
    "print(\"linearsvr mae: {:3.2f}\".format(lsvrmae))\n",
    "print(\"linearsvr r2: {:3.2f}\".format(lsvr2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The LinearSVR model performed the best and there are no differences between the true and predicted values and we could not score a higher r2(coefficient of determination) value than I accomplished . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
